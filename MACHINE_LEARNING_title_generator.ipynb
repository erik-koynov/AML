{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train models for title generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn import preprocessing as skp\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from nltk.translate import bleu_score\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('disk/ERIK_ML/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_padded.npy')\n",
    "X_test = np.load('X_test_padded.npy')\n",
    "titles_train_input = np.load('titles_train_input_padded.npy')\n",
    "titles_train_output = np.load('titles_train_output_padded.npy')\n",
    "titles_test_input = np.load('titles_test_input_padded.npy')\n",
    "titles_test_output = np.load('titles_test_output_padded.npy')\n",
    "embeddings = np.load('embeddings_classification.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('idx2word_titles.pkl','rb')\n",
    "idx2word_titles = pickle.load(f)\n",
    "f.close()\n",
    "NUM_EMBEDDINGS_TITLES = max(list(idx2word_titles.keys()))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('word2idx_titles.pkl','rb')\n",
    "word2idx_titles = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('word2idx_X.pkl','rb')\n",
    "word2idx_X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('idx2word_X.pkl','rb')\n",
    "idx2word_X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAINING = X_train.shape[0]\n",
    "N_TESTING = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.LongTensor(X_train).to(device),\n",
    "                           torch.LongTensor(titles_train_input).to(device),\n",
    "                           torch.LongTensor(titles_train_output).to(device))\n",
    "\n",
    "test_data = TensorDataset(torch.LongTensor(X_test).to(device),\n",
    "                          torch.LongTensor(titles_test_input).to(device),\n",
    "                          torch.LongTensor(titles_test_output).to(device))\n",
    "\n",
    "train_data_loader = DataLoader(train_data, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                shuffle=True)\n",
    "test_data_loader = DataLoader(test_data, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMBEDDINGS = embeddings.shape[0]\n",
    "N_DIM = embeddings.shape[1]\n",
    "HIDDEN_DIM = 128\n",
    "MAX_LEN_DECODER = 20\n",
    "MAX_LEN_ENCODER = X_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_layer,self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(NUM_EMBEDDINGS,N_DIM,_weight=torch.Tensor(embeddings).to(device))\n",
    "        self.lstm = torch.nn.LSTM(N_DIM,HIDDEN_DIM,bidirectional = True,batch_first = True)\n",
    "    def forward(self, input_):\n",
    "        input_ = self.embedding(input_)\n",
    "        #print('embedded size',input_.size())\n",
    "        full_sequence,b = self.lstm(input_)\n",
    "        #print('lstm sequences size',output.size()) [BATCH, SEQ_LEN, 256]\n",
    "        #print('lstm sequences last',output[0,0,128:])\n",
    "        #print('hidden state size : {}, cell state size : {}'.format(b[0].size(),b[1].size()))\n",
    "        #print('hidden state size : {}'.format(b[0][1,0]))\n",
    "        #print('series through linear : ',output.size())\n",
    "        #print(b[0].size()) [N_DIRECTIONS, BATCH, N_DIMS]\n",
    "        # concatenate the hidden states to use them later \n",
    "        last_hidden_state = torch.cat([b[0][0],b[0][1]],dim = -1)\n",
    "        #print(last_hidden_state.size()) # torch.Size([BATCH, 256])\n",
    "        return full_sequence, last_hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_layer,self).__init__()\n",
    "        self.sequence_transformer = nn.Linear(HIDDEN_DIM*2,HIDDEN_DIM)\n",
    "        self.last_state_transformer = nn.Linear(HIDDEN_DIM*2,HIDDEN_DIM)\n",
    "        self.dimension_reducer = nn.Linear(HIDDEN_DIM,1)\n",
    "    def forward(self, last_state, sequence):\n",
    "        last_state = last_state.view(last_state.size()[0],\n",
    "                                1,\n",
    "                                last_state.size()[1])\n",
    "        #print('new last state size: ',last_state.size()) # torch.Size([BATCH, 1, 512])\n",
    "        seq_logits = self.dimension_reducer(\n",
    "                    torch.tanh(\n",
    "                    self.sequence_transformer(sequence) + \n",
    "                    self.last_state_transformer(last_state)\n",
    "                    )\n",
    "        )\n",
    "        #print(seq_logits.size()) # ([BACH, SEQ_LEN, 1])\n",
    "        attention_weights = F.softmax(seq_logits,dim = 1)\n",
    "        #print(attention_weights.size()) # torch.Size([BATCH, SEQ_LEN, 1])\n",
    "        \n",
    "        context_vector = attention_weights*sequence\n",
    "        #print(context_vector.size()) # [BATCH, SEQ_LEN, HIDDEN_DIM*2]\n",
    "        context_vector = torch.sum(context_vector,dim = 1)\n",
    "        #print(context_vector.size()) # [BATCH, HIDDEN_DIM*2]\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_layer,self).__init__()\n",
    "        self.embedding = nn.Embedding(NUM_EMBEDDINGS_TITLES,N_DIM)\n",
    "        self.lstm = torch.nn.LSTM(N_DIM + 2*HIDDEN_DIM,HIDDEN_DIM*2,bidirectional = False,batch_first = True)\n",
    "        self.linear = nn.Linear(HIDDEN_DIM*2,NUM_EMBEDDINGS_TITLES)\n",
    "    def forward(self,input_, context, hidden_state, cell_state):#last_states):\n",
    "        \"\"\"\n",
    "        input_ [BATCH, 1]: sequence of word frequences [0...LEN_DICTIONARY]\n",
    "        context [BATCH, 2*HIDDEN_DIM]: the computed context vector (Attention Layer) [B,2*HIDDEN_DIM]\n",
    "        hidden_state : the last possible hidden state of the decoder\n",
    "        cell_state : the last possible cell state of the decoder\n",
    "        \"\"\"\n",
    "        '''\n",
    "        hidden_state = last_states[0]\n",
    "        cell_state = last_states[1]'''\n",
    "        input_ = self.embedding(input_) \n",
    "        #print('after embedding',input_.size()) #[BATCH, SEQ_LEN = 1 , N_DIM]\n",
    "        #print(context.unsqueeze(1).size()) #[BATCH, SEQ_LEN = 1, 256] \n",
    "        input_ = torch.cat([input_,context.unsqueeze(1)],dim = -1)\n",
    "        #print('after concatenation ',input_.size()) # [BATCH, SEQ_LEN = 1, 306]\n",
    "        #print(hidden_state.size()) # [DIRECTIONS, BATCH , 256]\n",
    "         \n",
    "        output, states = self.lstm(input_, (hidden_state, cell_state))\n",
    "\n",
    "        #print('after lstm ',output.size())[BATCH, SEQ_LEN, HIDDEN_DIM]\n",
    "       \n",
    "        output = self.linear(output)\n",
    "        #print('final output ',output.size()) [BATCH, SEQ_LEN, LEN_DICTIONARY]\n",
    "        hidden_state = states[0]\n",
    "        #print(hidden_state.size()) #[DIRECTIONS, BATCH, 256]\n",
    "        cell_state = states[1]\n",
    "        #print(cell_state.size()) [DIRECTIONS, BATCH, 256]\n",
    "        return output, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = Encoder_layer()\n",
    "        self.attention = Attention_layer()\n",
    "        self.decoder = Decoder_layer()\n",
    "    def forward(self, encoder_input, decoder_input, teacher_forcing = True):\n",
    "        \n",
    "        #print('input size',encoder_input.size())\n",
    "        full_sequence, last_hidden_state = self.encoder(encoder_input)\n",
    "        #print('full sequence size: ',full_sequence.size())\n",
    "        #print('last hidden state size : ',last_hidden_state.size())\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(\n",
    "                                        last_hidden_state,\n",
    "                                        full_sequence\n",
    "                                        )\n",
    "        #print('context vector size: ',context_vector.size())\n",
    "        #print('attention weights size: ', attention_weights.size()) [BATCH, SEQ_LEN, 1]\n",
    "        \n",
    "        all_attention_weights = torch.zeros(MAX_LEN_DECODER,\n",
    "                                            attention_weights.size()[0],\n",
    "                                            MAX_LEN_ENCODER,1\n",
    "                                            ).to(device)\n",
    "        #print(all_attention_weights.size()) [DEC_ML, BATCH, SEQ_LEN, 1]\n",
    "        all_attention_weights[0] = attention_weights\n",
    "        \n",
    "        output = self.decode(decoder_input,\n",
    "                                           full_sequence,\n",
    "                                           context_vector,\n",
    "                                           last_hidden_state,\n",
    "                                           teacher_forcing,\n",
    "                                           all_attention_weights)\n",
    "\n",
    "        \n",
    "        return output, all_attention_weights\n",
    "            \n",
    "    def decode(self,\n",
    "                             decoder_input,\n",
    "                             full_sequence,\n",
    "                             context_vector,\n",
    "                             last_hidden_state, \n",
    "                             teacher_forcing,\n",
    "                             all_attention_weights):\n",
    "        #print('initial input size: ',decoder_input[:,0].unsqueeze(1).size()) [BATCH, SEQUENCE]\n",
    "        output, hidden_state, cell_state = self.decoder(\n",
    "                                            decoder_input[:,0].unsqueeze(1),\n",
    "                                            context_vector,\n",
    "                                            last_hidden_state.unsqueeze(0),\n",
    "                                            torch.zeros_like(last_hidden_state).unsqueeze(0).to(device)\n",
    "                                                       )\n",
    "        output_new = output\n",
    "        for i in range(1,MAX_LEN_DECODER):\n",
    "            if teacher_forcing:\n",
    "                next_ = decoder_input[:,i].unsqueeze(1)\n",
    "            else:\n",
    "                # get the most probable word\n",
    "                next_ = torch.argmax(output_new,dim = -1)\n",
    "                #print('next_ size :',next_.size()) # [BATCH, 1]\n",
    "            context_vector, attention_weights = self.attention(\n",
    "                                        hidden_state.squeeze(),\n",
    "                                        full_sequence\n",
    "                                        )\n",
    "            output_new, hidden_state, cell_state = self.decoder(\n",
    "                                            next_,\n",
    "                                            context_vector,\n",
    "                                            hidden_state,\n",
    "                                            cell_state\n",
    "                                                       )\n",
    "            #print(output_new.size()) [BATCH, 1, LEN_DICT]\n",
    "            \n",
    "            output = torch.cat([output,output_new],dim = 1)\n",
    "            all_attention_weights[i] = attention_weights\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, optimizer):\n",
    "    training_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "        # loop over the training data\n",
    "        for X,input_,y in tqdm_notebook(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(X,input_,True)\n",
    "            predictions = torch.argmax(logits,dim = -1)\n",
    "            print(predictions.size())\n",
    "            break\n",
    "            # transform the tensors in order to make cross entropy\n",
    "            # calculation possible : logits [BATCH*SEQ_LEN x VOCAB] \n",
    "            # y [BATCH*SEQ_LEN]\n",
    "            cost = loss(logits.view(logits.size()[0]*logits.size()[1],NUM_EMBEDDINGS_TITLES),\n",
    "                        y.view(y.size()[0]*y.size()[1]))\n",
    "            cost.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss+=cost.item()\n",
    "        print('Training loss in the {}. epoch: '.format(epoch),epoch_loss/1329)\n",
    "        training_loss.append(epoch_loss/1329)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_(model):\n",
    "    all_texts = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_attention_weights = []\n",
    "    with torch.no_grad():\n",
    "        for X,input_,y in tqdm_notebook(test_data_loader):\n",
    "            logits, attention_weights = model(X,input_,False)\n",
    "            predictions = torch.argmax(logits,dim = -1)\n",
    "            all_predictions.append(predictions)\n",
    "            all_texts.append(X)\n",
    "            all_targets.append(y)\n",
    "            all_attention_weights.append(attention_weights)\n",
    "            \n",
    "            # transform the tensors in order to make cross entropy\n",
    "            # calculation possible : logits [BATCH*SEQ_LEN x VOCAB] \n",
    "            # y [BATCH*SEQ_LEN]\n",
    "    return all_predictions, all_texts, all_targets, all_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('generator/model_at_130_iteration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61569de2b5484ad9b97fe50d28b96ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=469), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_predictions, all_texts, all_targets, all_weights = eval_(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to texts\n",
    "texts = []\n",
    "i = 0\n",
    "for x in all_texts:\n",
    "    for text in x:\n",
    "        texts.append([])\n",
    "        for word in text:\n",
    "        \n",
    "            word = idx2word_X.get(word.item())\n",
    "            \n",
    "            if word != None:\n",
    "                   \n",
    "                texts[i].append(word)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(tensor_list):\n",
    "    all_preds = []\n",
    "    for y in tensor_list:\n",
    "        for y_ in y:\n",
    "            sentence = []\n",
    "            for i in y_:\n",
    "\n",
    "                word = idx2word_titles.get(i.item())\n",
    "                if word != None:\n",
    "                    if word == 'stop':\n",
    "                        break\n",
    "                    else:\n",
    "                        sentence.append(word)\n",
    "            all_preds.append(sentence)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds  = to_list(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_originals = to_list(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hausverkauf', 'wer', 'haftet', 'für', 'kredit', 'grundschuld']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[1310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ek/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ek/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ek/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_scores = [0.0]*4\n",
    "for y, pred in zip(all_originals,all_preds):\n",
    "    bleu_scores[0] += bleu_score.sentence_bleu([y],pred,(1.0,0.0,0.0,0.0)) # BLEU - 1\n",
    "    bleu_scores[1] += bleu_score.sentence_bleu([y],pred,(0.5,0.5,0.0,0.0))\n",
    "    bleu_scores[2] += bleu_score.sentence_bleu([y],pred,(0.33,0.33,0.33,0.0))\n",
    "    bleu_scores[3] += bleu_score.sentence_bleu([y],pred,(0.25,0.25,0.25,0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15513220212026252"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores[2]/len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18208950336285804"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores[1]/len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23613248720994706"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores[0]/len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11875126086649754"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores[3]/len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43923\n"
     ]
    }
   ],
   "source": [
    "print(NUM_EMBEDDINGS_TITLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
